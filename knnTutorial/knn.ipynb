{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# kNNアルゴリズムとは\n",
    "k近傍法(k-NearestNeighbor)アルゴリズムは、近接性を使用して個々のデータポイントのグループ化に関する分類または予測を行うノンパラメトリックな教師あり学習分類器である。\n",
    "kNNアルゴリズムは回帰問題にも分類問題にも利用できるが、通常は分類アルゴリズムとして使用される。\n",
    "基本的なアイデアは多数決である。カテゴリ数が2つの場合には「多数決」カテゴリ数がそれ以上の場合には「相対多数」と呼ばれる。あるデータポイントからk番目までに近いポイントのデータラベルの相対多数によって、そのデータポイントのラベルを決定する。\n",
    "kNNアルゴリズムは「遅延学習」と呼ばれる分類に属し、トレーニングを実行するのではなく、トレーニング・データセットの保存のみを実行する。これは分類または予測が行われているときにすべての計算が行われることを意味する。また、すべてのトレーニングデータをメモリーに乗せる必要があるため、インスタンス・ベース、またはメモリー・ベースの学習方法とも呼ばれる。これは他の分類器と比較してより多くのメモリとデータストレージを消費するアプローチである。\n",
    "\n",
    "# kNNの計算：距離メトリクス\n",
    "kNNアルゴリズムの目的は特定のデータポイントの最近傍を識別し、そのポイントにクラスラベルを割り当てることである。これを行うために調整する必要のあるハイパーパラメータは\n",
    "\n",
    "\n",
    "ノンパラメトリック：与えられた母集団が何らかの分布に従っている前提がない\n",
    "パラメトリック：与えられた母集団が何らかの分布に従っている前提がある（だいたい正規分布）\n",
    "回帰問題：入力データから数値の予測を行う問題。この場合与えられたデータポイントがどのグループに属するかを予測する\n",
    "分類問題：与えられたデータのデータポイントがそれぞれどこに属するか\n",
    "遅延学習：計算が必要になるまで計算を行なわない"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# コード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=1: Mean Accuracy=0.726, Std Dev=0.049\n",
      "k=2: Mean Accuracy=0.743, Std Dev=0.070\n",
      "k=3: Mean Accuracy=0.709, Std Dev=0.051\n",
      "k=4: Mean Accuracy=0.731, Std Dev=0.042\n",
      "k=5: Mean Accuracy=0.706, Std Dev=0.058\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from csv import reader\n",
    "from math import sqrt, exp\n",
    "from statistics import median\n",
    "from random import shuffle\n",
    "\n",
    "def load_csv(filename):\n",
    "    dataset = []\n",
    "    with open(filename, 'r') as file:\n",
    "        csv_reader = reader(file)\n",
    "        for row in csv_reader:\n",
    "            dataset.append([float(x) for x in row])\n",
    "    return dataset\n",
    "\n",
    "def euclidean_distance(row1, row2):\n",
    "    return sqrt(sum((r1 - r2) ** 2 for r1, r2 in zip(row1[1:], row2[1:])))\n",
    "\n",
    "def get_neighbors(train, test_row, k):\n",
    "    distances = [(train_row, euclidean_distance(test_row, train_row)) for train_row in train]\n",
    "    distances.sort(key=lambda x: x[1])\n",
    "    return distances[:k]\n",
    "\n",
    "def weighted_knn(train, test_row, k, sigma):\n",
    "    neighbors = get_neighbors(train, test_row, k)\n",
    "    class_votes = {}\n",
    "    for neighbor, distance in neighbors:\n",
    "        weight = exp(- (distance ** 2) / (2 * (sigma ** 2)))\n",
    "        class_votes[neighbor[0]] = class_votes.get(neighbor[0], 0) + weight\n",
    "    return max(class_votes, key=class_votes.get)\n",
    "\n",
    "def evaluate_knn(dataset, k, split_ratio=0.7, runs=10, weighted=False):\n",
    "    accuracy_list = []\n",
    "    for _ in range(runs):\n",
    "        shuffle(dataset)\n",
    "        train_size = int(len(dataset) * split_ratio)\n",
    "        train, test = dataset[:train_size], dataset[train_size:]\n",
    "        \n",
    "        if weighted:\n",
    "            distance_matrix = [euclidean_distance(a, b) for a in train for b in train if a != b]\n",
    "            sigma = median(distance_matrix)\n",
    "        \n",
    "        correct = 0\n",
    "        for test_row in test:\n",
    "            prediction = weighted_knn(train, test_row, k, sigma) if weighted else get_neighbors(train, test_row, 1)[0][0][0]\n",
    "            if prediction == test_row[0]:\n",
    "                correct += 1\n",
    "        accuracy_list.append(correct / len(test))\n",
    "    \n",
    "    mean_acc = np.mean(accuracy_list)\n",
    "    std_acc = np.std(accuracy_list)\n",
    "    return mean_acc, std_acc\n",
    "\n",
    "# Example usage\n",
    "filename = './hayuci13a/yXT_wine.csv'\n",
    "dataset = load_csv(filename)\n",
    "k_values = [1, 2, 3, 4, 5]\n",
    "\n",
    "for k in k_values:\n",
    "    mean_acc, std_acc = evaluate_knn(dataset, k, weighted=True)\n",
    "    print(f'k={k}: Mean Accuracy={mean_acc:.3f}, Std Dev={std_acc:.3f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [97.14285714285714, 91.42857142857143, 94.28571428571428, 94.28571428571428, 100.0]\n",
      "Mean Accuracy: 95.429%\n"
     ]
    }
   ],
   "source": [
    "from random import seed, randrange\n",
    "from csv import reader\n",
    "from math import sqrt\n",
    "\n",
    "def load_csv(filename):\n",
    "    dataset = list()\n",
    "    with open(filename, 'r') as file:\n",
    "        csv_reader = reader(file)\n",
    "        for row in csv_reader:\n",
    "            if not row:\n",
    "                continue\n",
    "            dataset.append(row)\n",
    "    return dataset\n",
    "\n",
    "# Convert string columns to float and adjust class label position\n",
    "def preprocess_dataset(dataset):\n",
    "    for row in dataset:\n",
    "        row[:] = [float(x) for x in row]  # Convert all to float\n",
    "        row.append(row.pop(0))  # Move class label to the end\n",
    "\n",
    "# Find the min and max values for each column\n",
    "def dataset_minmax(dataset):\n",
    "    minmax = [[min(col), max(col)] for col in zip(*dataset)]\n",
    "    return minmax\n",
    "\n",
    "# Rescale dataset columns to the range 0-1\n",
    "def normalize_dataset(dataset, minmax):\n",
    "    for row in dataset:\n",
    "        for i in range(len(row)-1):  # Exclude class label\n",
    "            row[i] = (row[i] - minmax[i][0]) / (minmax[i][1] - minmax[i][0])\n",
    "\n",
    "# Split a dataset into k folds\n",
    "def cross_validation_split(dataset, n_folds):\n",
    "    dataset_split = list()\n",
    "    dataset_copy = list(dataset)\n",
    "    fold_size = int(len(dataset) / n_folds)\n",
    "    for _ in range(n_folds):\n",
    "        fold = list()\n",
    "        while len(fold) < fold_size and dataset_copy:\n",
    "            index = randrange(len(dataset_copy))\n",
    "            fold.append(dataset_copy.pop(index))\n",
    "        dataset_split.append(fold)\n",
    "    return dataset_split\n",
    "\n",
    "# Calculate accuracy percentage\n",
    "def accuracy_metric(actual, predicted):\n",
    "    correct = sum(1 for a, p in zip(actual, predicted) if a == p)\n",
    "    return correct / len(actual) * 100.0\n",
    "\n",
    "# Evaluate an algorithm using a cross validation split\n",
    "def evaluate_algorithm(dataset, algorithm, n_folds, *args):\n",
    "    folds = cross_validation_split(dataset, n_folds)\n",
    "    scores = []\n",
    "    for fold in folds:\n",
    "        train_set = [row for f in folds if f is not fold for row in f]\n",
    "        test_set = [list(row) for row in fold]\n",
    "        for row in test_set:\n",
    "            row[-1] = None\n",
    "        predicted = algorithm(train_set, test_set, *args)\n",
    "        actual = [row[-1] for row in fold]\n",
    "        scores.append(accuracy_metric(actual, predicted))\n",
    "    return scores\n",
    "\n",
    "# Calculate Euclidean distance\n",
    "def euclidean_distance(row1, row2):\n",
    "    return sqrt(sum((row1[i] - row2[i])**2 for i in range(len(row1)-1)))\n",
    "\n",
    "# Locate the most similar neighbors\n",
    "def get_neighbors(train, test_row, num_neighbors):\n",
    "    distances = [(train_row, euclidean_distance(test_row, train_row)) for train_row in train]\n",
    "    distances.sort(key=lambda tup: tup[1])\n",
    "    return [distances[i][0] for i in range(num_neighbors)]\n",
    "\n",
    "# Make a prediction with neighbors\n",
    "def predict_classification(train, test_row, num_neighbors):\n",
    "    neighbors = get_neighbors(train, test_row, num_neighbors)\n",
    "    output_values = [row[-1] for row in neighbors]\n",
    "    return max(set(output_values), key=output_values.count)\n",
    "\n",
    "# kNN Algorithm\n",
    "def k_nearest_neighbors(train, test, num_neighbors):\n",
    "    return [predict_classification(train, row, num_neighbors) for row in test]\n",
    "\n",
    "# Load and prepare data\n",
    "seed(1)\n",
    "filename = './hayuci13a/yXT_wine.csv'  # 修正されたデータセット名\n",
    "dataset = load_csv(filename)\n",
    "preprocess_dataset(dataset)  # データを変換\n",
    "minmax = dataset_minmax(dataset)\n",
    "normalize_dataset(dataset, minmax)\n",
    "\n",
    "# Evaluate algorithm\n",
    "n_folds = 5\n",
    "num_neighbors = 5\n",
    "scores = evaluate_algorithm(dataset, k_nearest_neighbors, n_folds, num_neighbors)\n",
    "print(f'Scores: {scores}')\n",
    "print(f'Mean Accuracy: {sum(scores)/len(scores):.3f}%')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
