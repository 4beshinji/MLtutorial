{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: (147, 7)\n",
      "Test set size: (63, 7)\n",
      "Class distribution in train set: [97 50]\n",
      "Class distribution in test set: [43 20]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "#load the dataset\n",
    "dataset = pd.read_csv('./hayuci13a/yXT_seeds.csv', header=None)\n",
    "df = dataset.iloc[:, 1:]\n",
    "df.head()\n",
    "labels = dataset.iloc[:,0]\n",
    "\n",
    "# Identify the most frequent class\n",
    "unique, counts = np.unique(labels, return_counts=True)\n",
    "positive_class = unique[np.argmax(counts)]\n",
    "\n",
    "# Convert to binary classification\n",
    "y_binary = np.where(labels == positive_class, 1, 0)\n",
    "\n",
    "#Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df, y_binary, test_size=0.3, random_state=42)\n",
    "\n",
    "#standardize the feautures\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.fit_transform(X_test)\n",
    "\n",
    "# Print dataset info\n",
    "print(\"Train set size:\", X_train.shape)\n",
    "print(\"Test set size:\", X_test.shape)\n",
    "print(\"Class distribution in train set:\", np.bincount(y_train))\n",
    "print(\"Class distribution in test set:\", np.bincount(y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: (147, 7)\n",
      "Test set size: (63, 7)\n",
      "Class distribution in train set: [97 50]\n",
      "Class distribution in test set: [43 20]\n",
      "Test set accuracy: 0.6984126984126984\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#train a linear SVM with regularization paramater with lambda = 1/n\n",
    "n_train = X_train.shape[0]\n",
    "svm_model = SVC(kernel='linear', C=1/n_train, random_state=42)\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "#evaluate performance on the test set\n",
    "y_pred = svm_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test,y_pred)\n",
    "\n",
    "\n",
    "# Print dataset info and accuracy\n",
    "print(\"Train set size:\", X_train.shape)\n",
    "print(\"Test set size:\", X_test.shape)\n",
    "print(\"Class distribution in train set:\", np.bincount(y_train))\n",
    "print(\"Class distribution in test set:\", np.bincount(y_test))\n",
    "print(\"Test set accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: (147, 7)\n",
      "Test set size: (63, 7)\n",
      "Class distribution in train set: [97 50]\n",
      "Class distribution in test set: [43 20]\n",
      "Most frequent class (positive class): 1\n",
      "Best lambda (Standardization): 0.06802721088435375\n",
      "Best lambda (L1 Normalization): 0.0006802721088435375\n",
      "Best lambda (L2 Normalization): 0.06802721088435375\n",
      "Test set accuracy (Standardization): 0.8888888888888888\n",
      "Test set accuracy (L1 Normalization): 0.6825396825396826\n",
      "Test set accuracy (L2 Normalization): 0.8888888888888888\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "#standardize the feautures\n",
    "scaler = StandardScaler()\n",
    "X_train_std = scaler.fit_transform(X_train)\n",
    "X_test_std = scaler.fit_transform(X_test)\n",
    "\n",
    "# L1 Normalization\n",
    "l1_normalizer = Normalizer(norm='l1')\n",
    "X_train_l1 = l1_normalizer.fit_transform(X_train)\n",
    "X_test_l1 = l1_normalizer.transform(X_test)\n",
    "\n",
    "# L2 Normalization\n",
    "l2_normalizer = Normalizer(norm='l2')\n",
    "X_train_l2 = l2_normalizer.fit_transform(X_train)\n",
    "X_test_l2 = l2_normalizer.transform(X_test)\n",
    "\n",
    "#candidata values for lambda\n",
    "n_train = X_train.shape[0]\n",
    "lambda_values = [0.1/n_train, 1/n_train, 10/n_train]\n",
    "\n",
    "#perform five-fold cross-validation to select the best lambda\n",
    "\n",
    "def cross_validate_svm(X_train, y_train):\n",
    "    best_lambda = None\n",
    "    best_score = 0\n",
    "    for C in lambda_values:\n",
    "        svm = SVC(kernel='linear', C=C, random_state=42)\n",
    "        scores = cross_val_score(svm, X_train, y_train, cv=5, scoring='accuracy')\n",
    "        mean_score = scores.mean()\n",
    "        if mean_score > best_score:\n",
    "            best_score = mean_score\n",
    "            best_lambda = C\n",
    "    return best_lambda\n",
    "\n",
    "## Get best lambda for each normalization method\n",
    "best_lambda_std = cross_validate_svm(X_train_std, y_train)\n",
    "best_lambda_l1 = cross_validate_svm(X_train_l1, y_train)\n",
    "best_lambda_l2 = cross_validate_svm(X_train_l2, y_train)\n",
    "\n",
    "\n",
    "#train and evaluate SVM with best lambda for each method\n",
    "svm_std = SVC(kernel='linear', C=best_lambda_std, random_state=42)\n",
    "svm_std.fit(X_train_std, y_train)\n",
    "y_pred_std = svm_std.predict(X_test_std)\n",
    "accuracy_std = accuracy_score(y_test, y_pred_std)\n",
    "\n",
    "svm_l1 = SVC(kernel='linear', C=best_lambda_l1, random_state=42)\n",
    "svm_l1.fit(X_train_l1, y_train)\n",
    "y_pred_l1 = svm_l1.predict(X_test_l1)\n",
    "accuracy_l1 = accuracy_score(y_test, y_pred_l1)\n",
    "\n",
    "svm_l2 = SVC(kernel='linear', C=best_lambda_l2, random_state=42)\n",
    "svm_l2.fit(X_train_l2, y_train)\n",
    "y_pred_l2 = svm_l2.predict(X_test_l2)\n",
    "accuracy_l2 = accuracy_score(y_test, y_pred_l2)\n",
    "\n",
    "# Print results\n",
    "print(\"Train set size:\", X_train.shape)\n",
    "print(\"Test set size:\", X_test.shape)\n",
    "print(\"Class distribution in train set:\", np.bincount(y_train))\n",
    "print(\"Class distribution in test set:\", np.bincount(y_test))\n",
    "print(\"Most frequent class (positive class):\", positive_class)\n",
    "print(\"Best lambda (Standardization):\", best_lambda_std)\n",
    "print(\"Best lambda (L1 Normalization):\", best_lambda_l1)\n",
    "print(\"Best lambda (L2 Normalization):\", best_lambda_l2)\n",
    "print(\"Test set accuracy (Standardization):\", accuracy_std)\n",
    "print(\"Test set accuracy (L1 Normalization):\", accuracy_l1)\n",
    "print(\"Test set accuracy (L2 Normalization):\", accuracy_l2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracies: {'Standardization': np.float64(0.9048275862068967), 'L1 Normalization': np.float64(0.9117241379310345), 'L2 Normalization': np.float64(0.9050574712643679)}\n",
      "Best method: L1 Normalization\n",
      "t-test L1 Normalization vs Standardization: t=-186355846649807.9688, p=0.0000\n",
      "-> The difference between L1 Normalization and Standardization is statistically significant (p < 0.05).\n",
      "t-test L1 Normalization vs L2 Normalization: t=-inf, p=0.0000\n",
      "-> The difference between L1 Normalization and L2 Normalization is statistically significant (p < 0.05).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sin/code/MLtutorial/.venv/lib/python3.12/site-packages/scipy/stats/_axis_nan_policy.py:586: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  res = hypotest_fun_out(*samples, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import ttest_1samp\n",
    "\n",
    "\n",
    "accuracy_scores = {\n",
    "    \"Standardization\": [],\n",
    "    \"L1 Normalization\": [],\n",
    "    \"L2 Normalization\": []\n",
    "}\n",
    "\n",
    "# 10回のクロスバリデーション\n",
    "for _ in range(10):\n",
    "    for method, X_train in zip(accuracy_scores.keys(), [X_train_std, X_train_l1, X_train_l2]):\n",
    "        svm = SVC(kernel='linear', C=1.0, random_state=42)\n",
    "        scores = cross_val_score(svm, X_train, y_train, cv=5, scoring='accuracy')\n",
    "        accuracy_scores[method].append(scores.mean())\n",
    "\n",
    "# 平均精度を計算\n",
    "mean_accuracies = {method: np.mean(scores) for method, scores in accuracy_scores.items()}\n",
    "best_method = max(mean_accuracies, key=mean_accuracies.get)\n",
    "\n",
    "print(\"Average accuracies:\", mean_accuracies)\n",
    "print(\"Best method:\", best_method)\n",
    "\n",
    "# 最良手法と他の手法のt検定\n",
    "best_scores = np.array(accuracy_scores[best_method])\n",
    "for method, scores in accuracy_scores.items():\n",
    "    if method != best_method:\n",
    "        t_stat, p_value = ttest_1samp(scores, best_scores.mean())\n",
    "        print(f\"t-test {best_method} vs {method}: t={t_stat:.4f}, p={p_value:.4f}\")\n",
    "\n",
    "        if p_value < 0.05:\n",
    "            print(f\"-> The difference between {best_method} and {method} is statistically significant (p < 0.05).\")\n",
    "        else:\n",
    "            print(f\"-> No significant difference found between {best_method} and {method}.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# １標本のt検定とは？\n",
    "仮説：\n",
    "母集団の平均はある値をとる\n",
    "\n",
    "必要なデータ：\n",
    "- 独立\n",
    "- 連続変数\n",
    "- 標本が母集団から単純無作為抽出されている\n",
    "- 母集団は正規分布に従うことを想定｀"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
